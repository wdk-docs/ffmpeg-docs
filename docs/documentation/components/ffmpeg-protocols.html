

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="zh-CN" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="zh-CN" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>FFmpeg Protocols Documentation &mdash; ffmpeg-docs v2019.06.09 文档</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../../_static/jquery.js"></script>
        <script type="text/javascript" src="../../_static/underscore.js"></script>
        <script type="text/javascript" src="../../_static/doctools.js"></script>
        <script type="text/javascript" src="../../_static/language_data.js"></script>
        <script type="text/javascript" src="../../_static/translations.js"></script>
    
    <script type="text/javascript" src="../../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="author" title="关于这些文档" href="../../about.html" />
    <link rel="index" title="索引" href="../../genindex.html" />
    <link rel="search" title="搜索" href="../../search.html" />
    <link rel="next" title="FFmpeg Devices Documentation" href="ffmpeg-devices.html" />
    <link rel="prev" title="FFmpeg Formats Documentation" href="ffmpeg-formats.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../contents.html" class="icon icon-home"> ffmpeg-docs
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../index.html">FFmpeg</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../about.html">关于FFmpeg</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../index.html">文档</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../index.html#command-line-tools-documentation">Command Line Tools Documentation</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="../index.html#components-documentation">Components Documentation</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="ffmpeg-utils.html">FFmpeg Utilities Documentation</a></li>
<li class="toctree-l3"><a class="reference internal" href="ffmpeg-scaler.html">FFmpeg Scaler Documentation</a></li>
<li class="toctree-l3"><a class="reference internal" href="ffmpeg-resampler.html">FFmpeg Resampler Documentation</a></li>
<li class="toctree-l3"><a class="reference internal" href="ffmpeg-codecs.html">FFmpeg Codecs Documentation</a></li>
<li class="toctree-l3"><a class="reference internal" href="ffmpeg-bitstream-filters.html">FFmpeg Bitstream Filters Documentation</a></li>
<li class="toctree-l3"><a class="reference internal" href="ffmpeg-formats.html">FFmpeg Formats Documentation</a></li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">FFmpeg Protocols Documentation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#description">1 Description</a></li>
<li class="toctree-l4"><a class="reference internal" href="#protocol-options">2 Protocol Options</a></li>
<li class="toctree-l4"><a class="reference internal" href="#protocols">3 Protocols</a></li>
<li class="toctree-l4"><a class="reference internal" href="#see-also">4 See Also</a></li>
<li class="toctree-l4"><a class="reference internal" href="#authors">5 Authors</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="ffmpeg-devices.html">FFmpeg Devices Documentation</a></li>
<li class="toctree-l3"><a class="reference internal" href="ffmpeg-filters.html">FFmpeg Filters Documentation</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../index.html#libraries-documentation">Libraries Documentation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../index.html#general-documentation">General Documentation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../index.html#api-documentation">API Documentation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../index.html#community-contributed-documentation">Community Contributed Documentation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../index.html#books-about-ffmpeg">Books about FFmpeg</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../download.html">下载FFmpeg</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../news.html">新闻</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../contact.html">联系我们</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../bugreports.html">错误报告</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../wiki.html">欢迎来到FFmpeg Bug Tracker和Wiki</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../donations.html">捐赠</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../consulting.html">与FFmpeg相关的咨询和就业机会</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../security.html">FFmpeg安全</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../legal.html">FFmpeg许可和法律注意事项</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../contents.html">ffmpeg-docs</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../contents.html">Docs</a> &raquo;</li>
        
          <li><a href="../index.html">文档</a> &raquo;</li>
        
      <li>FFmpeg Protocols Documentation</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../../_sources/documentation/components/ffmpeg-protocols.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="ffmpeg-protocols-documentation">
<h1>FFmpeg Protocols Documentation<a class="headerlink" href="#ffmpeg-protocols-documentation" title="永久链接至标题">¶</a></h1>
<p>Table of Contents
1 Description
2 Protocol Options
3 Protocols
3.1 async
3.2 bluray
3.3 cache
3.4 concat
3.5 crypto
3.6 data
3.7 file
3.8 ftp
3.9 gopher
3.10 hls
3.11 http
3.11.1 HTTP Cookies
3.12 Icecast
3.13 mmst
3.14 mmsh
3.15 md5
3.16 pipe
3.17 prompeg
3.18 rtmp
3.19 rtmpe
3.20 rtmps
3.21 rtmpt
3.22 rtmpte
3.23 rtmpts
3.24 libsmbclient
3.25 libssh
3.26 librtmp rtmp, rtmpe, rtmps, rtmpt, rtmpte
3.27 rtp
3.28 rtsp
3.28.1 Examples
3.29 sap
3.29.1 Muxer
3.29.2 Demuxer
3.30 sctp
3.31 srt
3.32 srtp
3.33 subfile
3.34 tee
3.35 tcp
3.36 tls
3.37 udp
3.37.1 Examples
3.38 unix
4 See Also
5 Authors</p>
<div class="section" id="description">
<h2>1 Description<a class="headerlink" href="#description" title="永久链接至标题">¶</a></h2>
<p>This document describes the input and output protocols provided by the libavformat library.</p>
</div>
<div class="section" id="protocol-options">
<h2>2 Protocol Options<a class="headerlink" href="#protocol-options" title="永久链接至标题">¶</a></h2>
<p>The libavformat library provides some generic global options, which can be set on all the protocols. In addition each protocol may support so-called private options, which are specific for that component.</p>
<p>Options may be set by specifying -option value in the FFmpeg tools, or by setting the value explicitly in the AVFormatContext options or using the libavutil/opt.h API for programmatic use.</p>
<p>The list of supported options follows:</p>
<p>protocol_whitelist list (input)
Set a “,”-separated list of allowed protocols. “ALL” matches all protocols. Protocols prefixed by “-” are disabled. All protocols are allowed by default but protocols used by an another protocol (nested protocols) are restricted to a per protocol subset.</p>
</div>
<div class="section" id="protocols">
<h2>3 Protocols<a class="headerlink" href="#protocols" title="永久链接至标题">¶</a></h2>
<p>Protocols are configured elements in FFmpeg that enable access to resources that require specific protocols.</p>
<p>When you configure your FFmpeg build, all the supported protocols are enabled by default. You can list all available ones using the configure option “–list-protocols”.</p>
<p>You can disable all the protocols using the configure option “–disable-protocols”, and selectively enable a protocol using the option “–enable-protocol=PROTOCOL”, or you can disable a particular protocol using the option “–disable-protocol=PROTOCOL”.</p>
<p>The option “-protocols” of the ff* tools will display the list of supported protocols.</p>
<p>All protocols accept the following options:</p>
<p>rw_timeout
Maximum time to wait for (network) read/write operations to complete, in microseconds.</p>
<p>A description of the currently available protocols follows.</p>
<p>3.1 async
Asynchronous data filling wrapper for input stream.</p>
<p>Fill data in a background thread, to decouple I/O operation from demux thread.</p>
<p>async:URL
async:http://host/resource
async:cache:http://host/resource
3.2 bluray
Read BluRay playlist.</p>
<p>The accepted options are:</p>
<p>angle
BluRay angle</p>
<p>chapter
Start chapter (1…N)</p>
<p>playlist
Playlist to read (BDMV/PLAYLIST/?????.mpls)</p>
<p>Examples:</p>
<p>Read longest playlist from BluRay mounted to /mnt/bluray:</p>
<p>bluray:/mnt/bluray
Read angle 2 of playlist 4 from BluRay mounted to /mnt/bluray, start from chapter 2:</p>
<p>-playlist 4 -angle 2 -chapter 2 bluray:/mnt/bluray
3.3 cache
Caching wrapper for input stream.</p>
<p>Cache the input stream to temporary file. It brings seeking capability to live streams.</p>
<p>cache:URL
3.4 concat
Physical concatenation protocol.</p>
<p>Read and seek from many resources in sequence as if they were a unique resource.</p>
<p>A URL accepted by this protocol has the syntax:</p>
<p>concat:URL1|URL2|…|URLN
where URL1, URL2, …, URLN are the urls of the resource to be concatenated, each one possibly specifying a distinct protocol.</p>
<p>For example to read a sequence of files split1.mpeg, split2.mpeg, split3.mpeg with ffplay use the command:</p>
<p>ffplay concat:split1.mpeg|split2.mpeg|split3.mpeg
Note that you may need to escape the character “|” which is special for many shells.</p>
<p>3.5 crypto
AES-encrypted stream reading protocol.</p>
<p>The accepted options are:</p>
<p>key
Set the AES decryption key binary block from given hexadecimal representation.</p>
<p>iv
Set the AES decryption initialization vector binary block from given hexadecimal representation.</p>
<p>Accepted URL formats:</p>
<p>crypto:URL
crypto+URL
3.6 data
Data in-line in the URI. See http://en.wikipedia.org/wiki/Data_URI_scheme.</p>
<p>For example, to convert a GIF file given inline with ffmpeg:</p>
<p>ffmpeg -i “<a class="reference external" href="data:image/gif;base64,R0lGODdhCAAIAMIEAAAAAAAA//8AAP//AP///////////////ywAAAAACAAIAAADF0gEDLojDgdGiJdJqUX02iB4E8Q9jUMkADs=">data:image/gif;base64,R0lGODdhCAAIAMIEAAAAAAAA//8AAP//AP///////////////ywAAAAACAAIAAADF0gEDLojDgdGiJdJqUX02iB4E8Q9jUMkADs=</a>” smiley.png
3.7 file
File access protocol.</p>
<p>Read from or write to a file.</p>
<p>A file URL can have the form:</p>
<p><a class="reference external" href="file:filename">file:filename</a>
where filename is the path of the file to read.</p>
<p>An URL that does not have a protocol prefix will be assumed to be a file URL. Depending on the build, an URL that looks like a Windows path with the drive letter at the beginning will also be assumed to be a file URL (usually not the case in builds for unix-like systems).</p>
<p>For example to read from a file input.mpeg with ffmpeg use the command:</p>
<p>ffmpeg -i <a class="reference external" href="file:input.mpeg">file:input.mpeg</a> output.mpeg
This protocol accepts the following options:</p>
<p>truncate
Truncate existing files on write, if set to 1. A value of 0 prevents truncating. Default value is 1.</p>
<p>blocksize
Set I/O operation maximum block size, in bytes. Default value is INT_MAX, which results in not limiting the requested block size. Setting this value reasonably low improves user termination request reaction time, which is valuable for files on slow medium.</p>
<p>follow
If set to 1, the protocol will retry reading at the end of the file, allowing reading files that still are being written. In order for this to terminate, you either need to use the rw_timeout option, or use the interrupt callback (for API users).</p>
<p>seekable
Controls if seekability is advertised on the file. 0 means non-seekable, -1 means auto (seekable for normal files, non-seekable for named pipes).</p>
<p>Many demuxers handle seekable and non-seekable resources differently, overriding this might speed up opening certain files at the cost of losing some features (e.g. accurate seeking).</p>
<p>3.8 ftp
FTP (File Transfer Protocol).</p>
<p>Read from or write to remote resources using FTP protocol.</p>
<p>Following syntax is required.</p>
<p><a class="reference external" href="ftp://[user[:password]&#64;]server[:port]/path/to/remote/resource.mpeg">ftp://[user[:password]&#64;]server[:port]/path/to/remote/resource.mpeg</a>
This protocol accepts the following options.</p>
<p>timeout
Set timeout in microseconds of socket I/O operations used by the underlying low level operation. By default it is set to -1, which means that the timeout is not specified.</p>
<p>ftp-anonymous-password
Password used when login as anonymous user. Typically an e-mail address should be used.</p>
<p>ftp-write-seekable
Control seekability of connection during encoding. If set to 1 the resource is supposed to be seekable, if set to 0 it is assumed not to be seekable. Default value is 0.</p>
<p>NOTE: Protocol can be used as output, but it is recommended to not do it, unless special care is taken (tests, customized server configuration etc.). Different FTP servers behave in different way during seek operation. ff* tools may produce incomplete content due to server limitations.</p>
<p>3.9 gopher
Gopher protocol.</p>
<p>3.10 hls
Read Apple HTTP Live Streaming compliant segmented stream as a uniform one. The M3U8 playlists describing the segments can be remote HTTP resources or local files, accessed using the standard file protocol. The nested protocol is declared by specifying “+proto” after the hls URI scheme name, where proto is either “file” or “http”.</p>
<p>hls+http://host/path/to/remote/resource.m3u8
hls+file://path/to/local/resource.m3u8
Using this protocol is discouraged - the hls demuxer should work just as well (if not, please report the issues) and is more complete. To use the hls demuxer instead, simply use the direct URLs to the m3u8 files.</p>
<p>3.11 http
HTTP (Hyper Text Transfer Protocol).</p>
<p>This protocol accepts the following options:</p>
<p>seekable
Control seekability of connection. If set to 1 the resource is supposed to be seekable, if set to 0 it is assumed not to be seekable, if set to -1 it will try to autodetect if it is seekable. Default value is -1.</p>
<p>chunked_post
If set to 1 use chunked Transfer-Encoding for posts, default is 1.</p>
<p>content_type
Set a specific content type for the POST messages or for listen mode.</p>
<p>http_proxy
set HTTP proxy to tunnel through e.g. <a class="reference external" href="http://example.com:1234">http://example.com:1234</a></p>
<p>headers
Set custom HTTP headers, can override built in default headers. The value must be a string encoding the headers.</p>
<p>multiple_requests
Use persistent connections if set to 1, default is 0.</p>
<p>post_data
Set custom HTTP post data.</p>
<p>referer
Set the Referer header. Include ’Referer: URL’ header in HTTP request.</p>
<p>user_agent
Override the User-Agent header. If not specified the protocol will use a string describing the libavformat build. (“Lavf/&lt;version&gt;”)</p>
<p>user-agent
This is a deprecated option, you can use user_agent instead it.</p>
<p>timeout
Set timeout in microseconds of socket I/O operations used by the underlying low level operation. By default it is set to -1, which means that the timeout is not specified.</p>
<p>reconnect_at_eof
If set then eof is treated like an error and causes reconnection, this is useful for live / endless streams.</p>
<p>reconnect_streamed
If set then even streamed/non seekable streams will be reconnected on errors.</p>
<p>reconnect_delay_max
Sets the maximum delay in seconds after which to give up reconnecting</p>
<p>mime_type
Export the MIME type.</p>
<p>http_version
Exports the HTTP response version number. Usually “1.0” or “1.1”.</p>
<p>icy
If set to 1 request ICY (SHOUTcast) metadata from the server. If the server supports this, the metadata has to be retrieved by the application by reading the icy_metadata_headers and icy_metadata_packet options. The default is 1.</p>
<p>icy_metadata_headers
If the server supports ICY metadata, this contains the ICY-specific HTTP reply headers, separated by newline characters.</p>
<p>icy_metadata_packet
If the server supports ICY metadata, and icy was set to 1, this contains the last non-empty metadata packet sent by the server. It should be polled in regular intervals by applications interested in mid-stream metadata updates.</p>
<p>cookies
Set the cookies to be sent in future requests. The format of each cookie is the same as the value of a Set-Cookie HTTP response field. Multiple cookies can be delimited by a newline character.</p>
<p>offset
Set initial byte offset.</p>
<p>end_offset
Try to limit the request to bytes preceding this offset.</p>
<p>method
When used as a client option it sets the HTTP method for the request.</p>
<p>When used as a server option it sets the HTTP method that is going to be expected from the client(s). If the expected and the received HTTP method do not match the client will be given a Bad Request response. When unset the HTTP method is not checked for now. This will be replaced by autodetection in the future.</p>
<p>listen
If set to 1 enables experimental HTTP server. This can be used to send data when used as an output option, or read data from a client with HTTP POST when used as an input option. If set to 2 enables experimental multi-client HTTP server. This is not yet implemented in ffmpeg.c and thus must not be used as a command line option.</p>
<p># Server side (sending):
ffmpeg -i somefile.ogg -c copy -listen 1 -f ogg <a class="reference external" href="http://server:port">http://server:port</a></p>
<p># Client side (receiving):
ffmpeg -i <a class="reference external" href="http://server:port">http://server:port</a> -c copy somefile.ogg</p>
<p># Client can also be done with wget:
wget <a class="reference external" href="http://server:port">http://server:port</a> -O somefile.ogg</p>
<p># Server side (receiving):
ffmpeg -listen 1 -i <a class="reference external" href="http://server:port">http://server:port</a> -c copy somefile.ogg</p>
<p># Client side (sending):
ffmpeg -i somefile.ogg -chunked_post 0 -c copy -f ogg <a class="reference external" href="http://server:port">http://server:port</a></p>
<p># Client can also be done with wget:
wget –post-file=somefile.ogg <a class="reference external" href="http://server:port">http://server:port</a>
send_expect_100
Send an Expect: 100-continue header for POST. If set to 1 it will send, if set to 0 it won’t, if set to -1 it will try to send if it is applicable. Default value is -1.</p>
<p>3.11.1 HTTP Cookies
Some HTTP requests will be denied unless cookie values are passed in with the request. The cookies option allows these cookies to be specified. At the very least, each cookie must specify a value along with a path and domain. HTTP requests that match both the domain and path will automatically include the cookie value in the HTTP Cookie header field. Multiple cookies can be delimited by a newline.</p>
<p>The required syntax to play a stream specifying a cookie is:</p>
<p>ffplay -cookies “nlqptid=nltid=tsn; path=/; domain=somedomain.com;” <a class="reference external" href="http://somedomain.com/somestream.m3u8">http://somedomain.com/somestream.m3u8</a>
3.12 Icecast
Icecast protocol (stream to Icecast servers)</p>
<p>This protocol accepts the following options:</p>
<p>ice_genre
Set the stream genre.</p>
<p>ice_name
Set the stream name.</p>
<p>ice_description
Set the stream description.</p>
<p>ice_url
Set the stream website URL.</p>
<p>ice_public
Set if the stream should be public. The default is 0 (not public).</p>
<p>user_agent
Override the User-Agent header. If not specified a string of the form “Lavf/&lt;version&gt;” will be used.</p>
<p>password
Set the Icecast mountpoint password.</p>
<p>content_type
Set the stream content type. This must be set if it is different from audio/mpeg.</p>
<p>legacy_icecast
This enables support for Icecast versions &lt; 2.4.0, that do not support the HTTP PUT method but the SOURCE method.</p>
<p>icecast://[username[:password]&#64;]server:port/mountpoint
3.13 mmst
MMS (Microsoft Media Server) protocol over TCP.</p>
<p>3.14 mmsh
MMS (Microsoft Media Server) protocol over HTTP.</p>
<p>The required syntax is:</p>
<p>mmsh://server[:port][/app][/playpath]
3.15 md5
MD5 output protocol.</p>
<p>Computes the MD5 hash of the data to be written, and on close writes this to the designated output or stdout if none is specified. It can be used to test muxers without writing an actual file.</p>
<p>Some examples follow.</p>
<p># Write the MD5 hash of the encoded AVI file to the file output.avi.md5.
ffmpeg -i input.flv -f avi -y <a class="reference external" href="md5:output.avi.md5">md5:output.avi.md5</a></p>
<p># Write the MD5 hash of the encoded AVI file to stdout.
ffmpeg -i input.flv -f avi -y md5:
Note that some formats (typically MOV) require the output protocol to be seekable, so they will fail with the MD5 output protocol.</p>
<p>3.16 pipe
UNIX pipe access protocol.</p>
<p>Read and write from UNIX pipes.</p>
<p>The accepted syntax is:</p>
<p>pipe:[number]
number is the number corresponding to the file descriptor of the pipe (e.g. 0 for stdin, 1 for stdout, 2 for stderr). If number is not specified, by default the stdout file descriptor will be used for writing, stdin for reading.</p>
<p>For example to read from stdin with ffmpeg:</p>
<p>cat test.wav | ffmpeg -i pipe:0
# …this is the same as…
cat test.wav | ffmpeg -i pipe:
For writing to stdout with ffmpeg:</p>
<p>ffmpeg -i test.wav -f avi pipe:1 | cat &gt; test.avi
# …this is the same as…
ffmpeg -i test.wav -f avi pipe: | cat &gt; test.avi
This protocol accepts the following options:</p>
<p>blocksize
Set I/O operation maximum block size, in bytes. Default value is INT_MAX, which results in not limiting the requested block size. Setting this value reasonably low improves user termination request reaction time, which is valuable if data transmission is slow.</p>
<p>Note that some formats (typically MOV), require the output protocol to be seekable, so they will fail with the pipe output protocol.</p>
<p>3.17 prompeg
Pro-MPEG Code of Practice #3 Release 2 FEC protocol.</p>
<p>The Pro-MPEG CoP#3 FEC is a 2D parity-check forward error correction mechanism for MPEG-2 Transport Streams sent over RTP.</p>
<p>This protocol must be used in conjunction with the rtp_mpegts muxer and the rtp protocol.</p>
<p>The required syntax is:</p>
<p>-f rtp_mpegts -fec prompeg=option=val… rtp://hostname:port
The destination UDP ports are port + 2 for the column FEC stream and port + 4 for the row FEC stream.</p>
<p>This protocol accepts the following options:</p>
<p>l=n
The number of columns (4-20, LxD &lt;= 100)</p>
<p>d=n
The number of rows (4-20, LxD &lt;= 100)</p>
<p>Example usage:</p>
<p>-f rtp_mpegts -fec prompeg=l=8:d=4 rtp://hostname:port
3.18 rtmp
Real-Time Messaging Protocol.</p>
<p>The Real-Time Messaging Protocol (RTMP) is used for streaming multimedia content across a TCP/IP network.</p>
<p>The required syntax is:</p>
<p>rtmp://[username:password&#64;]server[:port][/app][/instance][/playpath]
The accepted parameters are:</p>
<p>username
An optional username (mostly for publishing).</p>
<p>password
An optional password (mostly for publishing).</p>
<p>server
The address of the RTMP server.</p>
<p>port
The number of the TCP port to use (by default is 1935).</p>
<p>app
It is the name of the application to access. It usually corresponds to the path where the application is installed on the RTMP server (e.g. /ondemand/, /flash/live/, etc.). You can override the value parsed from the URI through the rtmp_app option, too.</p>
<p>playpath
It is the path or name of the resource to play with reference to the application specified in app, may be prefixed by “mp4:”. You can override the value parsed from the URI through the rtmp_playpath option, too.</p>
<p>listen
Act as a server, listening for an incoming connection.</p>
<p>timeout
Maximum time to wait for the incoming connection. Implies listen.</p>
<p>Additionally, the following parameters can be set via command line options (or in code via AVOptions):</p>
<p>rtmp_app
Name of application to connect on the RTMP server. This option overrides the parameter specified in the URI.</p>
<p>rtmp_buffer
Set the client buffer time in milliseconds. The default is 3000.</p>
<p>rtmp_conn
Extra arbitrary AMF connection parameters, parsed from a string, e.g. like B:1 S:authMe O:1 NN:code:1.23 NS:flag:ok O:0. Each value is prefixed by a single character denoting the type, B for Boolean, N for number, S for string, O for object, or Z for null, followed by a colon. For Booleans the data must be either 0 or 1 for FALSE or TRUE, respectively. Likewise for Objects the data must be 0 or 1 to end or begin an object, respectively. Data items in subobjects may be named, by prefixing the type with ’N’ and specifying the name before the value (i.e. NB:myFlag:1). This option may be used multiple times to construct arbitrary AMF sequences.</p>
<p>rtmp_flashver
Version of the Flash plugin used to run the SWF player. The default is LNX 9,0,124,2. (When publishing, the default is FMLE/3.0 (compatible; &lt;libavformat version&gt;).)</p>
<p>rtmp_flush_interval
Number of packets flushed in the same request (RTMPT only). The default is 10.</p>
<p>rtmp_live
Specify that the media is a live stream. No resuming or seeking in live streams is possible. The default value is any, which means the subscriber first tries to play the live stream specified in the playpath. If a live stream of that name is not found, it plays the recorded stream. The other possible values are live and recorded.</p>
<p>rtmp_pageurl
URL of the web page in which the media was embedded. By default no value will be sent.</p>
<p>rtmp_playpath
Stream identifier to play or to publish. This option overrides the parameter specified in the URI.</p>
<p>rtmp_subscribe
Name of live stream to subscribe to. By default no value will be sent. It is only sent if the option is specified or if rtmp_live is set to live.</p>
<p>rtmp_swfhash
SHA256 hash of the decompressed SWF file (32 bytes).</p>
<p>rtmp_swfsize
Size of the decompressed SWF file, required for SWFVerification.</p>
<p>rtmp_swfurl
URL of the SWF player for the media. By default no value will be sent.</p>
<p>rtmp_swfverify
URL to player swf file, compute hash/size automatically.</p>
<p>rtmp_tcurl
URL of the target stream. Defaults to proto://host[:port]/app.</p>
<p>For example to read with ffplay a multimedia resource named “sample” from the application “vod” from an RTMP server “myserver”:</p>
<p>ffplay rtmp://myserver/vod/sample
To publish to a password protected server, passing the playpath and app names separately:</p>
<p>ffmpeg -re -i &lt;input&gt; -f flv -rtmp_playpath some/long/path -rtmp_app long/app/name rtmp://username:password&#64;myserver/
3.19 rtmpe
Encrypted Real-Time Messaging Protocol.</p>
<p>The Encrypted Real-Time Messaging Protocol (RTMPE) is used for streaming multimedia content within standard cryptographic primitives, consisting of Diffie-Hellman key exchange and HMACSHA256, generating a pair of RC4 keys.</p>
<p>3.20 rtmps
Real-Time Messaging Protocol over a secure SSL connection.</p>
<p>The Real-Time Messaging Protocol (RTMPS) is used for streaming multimedia content across an encrypted connection.</p>
<p>3.21 rtmpt
Real-Time Messaging Protocol tunneled through HTTP.</p>
<p>The Real-Time Messaging Protocol tunneled through HTTP (RTMPT) is used for streaming multimedia content within HTTP requests to traverse firewalls.</p>
<p>3.22 rtmpte
Encrypted Real-Time Messaging Protocol tunneled through HTTP.</p>
<p>The Encrypted Real-Time Messaging Protocol tunneled through HTTP (RTMPTE) is used for streaming multimedia content within HTTP requests to traverse firewalls.</p>
<p>3.23 rtmpts
Real-Time Messaging Protocol tunneled through HTTPS.</p>
<p>The Real-Time Messaging Protocol tunneled through HTTPS (RTMPTS) is used for streaming multimedia content within HTTPS requests to traverse firewalls.</p>
<p>3.24 libsmbclient
libsmbclient permits one to manipulate CIFS/SMB network resources.</p>
<p>Following syntax is required.</p>
<p><a class="reference external" href="smb://[[domain:]user[:password&#64;]]server[/share[/path[/file">smb://[[domain:]user[:password&#64;]]server[/share[/path[/file</a>]]]
This protocol accepts the following options.</p>
<p>timeout
Set timeout in milliseconds of socket I/O operations used by the underlying low level operation. By default it is set to -1, which means that the timeout is not specified.</p>
<p>truncate
Truncate existing files on write, if set to 1. A value of 0 prevents truncating. Default value is 1.</p>
<p>workgroup
Set the workgroup used for making connections. By default workgroup is not specified.</p>
<p>For more information see: <a class="reference external" href="http://www.samba.org/">http://www.samba.org/</a>.</p>
<p>3.25 libssh
Secure File Transfer Protocol via libssh</p>
<p>Read from or write to remote resources using SFTP protocol.</p>
<p>Following syntax is required.</p>
<p>sftp://[user[:password]&#64;]server[:port]/path/to/remote/resource.mpeg
This protocol accepts the following options.</p>
<p>timeout
Set timeout of socket I/O operations used by the underlying low level operation. By default it is set to -1, which means that the timeout is not specified.</p>
<p>truncate
Truncate existing files on write, if set to 1. A value of 0 prevents truncating. Default value is 1.</p>
<p>private_key
Specify the path of the file containing private key to use during authorization. By default libssh searches for keys in the ~/.ssh/ directory.</p>
<p>Example: Play a file stored on remote server.</p>
<p>ffplay sftp://user:password&#64;server_address:22/home/user/resource.mpeg
3.26 librtmp rtmp, rtmpe, rtmps, rtmpt, rtmpte
Real-Time Messaging Protocol and its variants supported through librtmp.</p>
<p>Requires the presence of the librtmp headers and library during configuration. You need to explicitly configure the build with “–enable-librtmp”. If enabled this will replace the native RTMP protocol.</p>
<p>This protocol provides most client functions and a few server functions needed to support RTMP, RTMP tunneled in HTTP (RTMPT), encrypted RTMP (RTMPE), RTMP over SSL/TLS (RTMPS) and tunneled variants of these encrypted types (RTMPTE, RTMPTS).</p>
<p>The required syntax is:</p>
<p>rtmp_proto://server[:port][/app][/playpath] options
where rtmp_proto is one of the strings “rtmp”, “rtmpt”, “rtmpe”, “rtmps”, “rtmpte”, “rtmpts” corresponding to each RTMP variant, and server, port, app and playpath have the same meaning as specified for the RTMP native protocol. options contains a list of space-separated options of the form key=val.</p>
<p>See the librtmp manual page (man 3 librtmp) for more information.</p>
<p>For example, to stream a file in real-time to an RTMP server using ffmpeg:</p>
<p>ffmpeg -re -i myfile -f flv rtmp://myserver/live/mystream
To play the same stream using ffplay:</p>
<p>ffplay “rtmp://myserver/live/mystream live=1”
3.27 rtp
Real-time Transport Protocol.</p>
<p>The required syntax for an RTP URL is: rtp://hostname[:port][?option=val…]</p>
<p>port specifies the RTP port to use.</p>
<p>The following URL options are supported:</p>
<p>ttl=n
Set the TTL (Time-To-Live) value (for multicast only).</p>
<p>rtcpport=n
Set the remote RTCP port to n.</p>
<p>localrtpport=n
Set the local RTP port to n.</p>
<p>localrtcpport=n’
Set the local RTCP port to n.</p>
<p>pkt_size=n
Set max packet size (in bytes) to n.</p>
<p>connect=0|1
Do a connect() on the UDP socket (if set to 1) or not (if set to 0).</p>
<p>sources=ip[,ip]
List allowed source IP addresses.</p>
<p>block=ip[,ip]
List disallowed (blocked) source IP addresses.</p>
<p>write_to_source=0|1
Send packets to the source address of the latest received packet (if set to 1) or to a default remote address (if set to 0).</p>
<p>localport=n
Set the local RTP port to n.</p>
<p>This is a deprecated option. Instead, localrtpport should be used.</p>
<p>Important notes:</p>
<p>If rtcpport is not set the RTCP port will be set to the RTP port value plus 1.
If localrtpport (the local RTP port) is not set any available port will be used for the local RTP and RTCP ports.
If localrtcpport (the local RTCP port) is not set it will be set to the local RTP port value plus 1.
3.28 rtsp
Real-Time Streaming Protocol.</p>
<p>RTSP is not technically a protocol handler in libavformat, it is a demuxer and muxer. The demuxer supports both normal RTSP (with data transferred over RTP; this is used by e.g. Apple and Microsoft) and Real-RTSP (with data transferred over RDT).</p>
<p>The muxer can be used to send a stream using RTSP ANNOUNCE to a server supporting it (currently Darwin Streaming Server and Mischa Spiegelmock’s RTSP server).</p>
<p>The required syntax for a RTSP url is:</p>
<p><a class="reference external" href="rtsp://hostname[:port]/path">rtsp://hostname[:port]/path</a>
Options can be set on the ffmpeg/ffplay command line, or set in code via AVOptions or in avformat_open_input.</p>
<p>The following options are supported.</p>
<p>initial_pause
Do not start playing the stream immediately if set to 1. Default value is 0.</p>
<p>rtsp_transport
Set RTSP transport protocols.</p>
<p>It accepts the following values:</p>
<p>‘udp’
Use UDP as lower transport protocol.</p>
<p>‘tcp’
Use TCP (interleaving within the RTSP control channel) as lower transport protocol.</p>
<p>‘udp_multicast’
Use UDP multicast as lower transport protocol.</p>
<p>‘http’
Use HTTP tunneling as lower transport protocol, which is useful for passing proxies.</p>
<p>Multiple lower transport protocols may be specified, in that case they are tried one at a time (if the setup of one fails, the next one is tried). For the muxer, only the ‘tcp’ and ‘udp’ options are supported.</p>
<p>rtsp_flags
Set RTSP flags.</p>
<p>The following values are accepted:</p>
<p>‘filter_src’
Accept packets only from negotiated peer address and port.</p>
<p>‘listen’
Act as a server, listening for an incoming connection.</p>
<p>‘prefer_tcp’
Try TCP for RTP transport first, if TCP is available as RTSP RTP transport.</p>
<p>Default value is ‘none’.</p>
<p>allowed_media_types
Set media types to accept from the server.</p>
<p>The following flags are accepted:</p>
<p>‘video’
‘audio’
‘data’
By default it accepts all media types.</p>
<p>min_port
Set minimum local UDP port. Default value is 5000.</p>
<p>max_port
Set maximum local UDP port. Default value is 65000.</p>
<p>timeout
Set maximum timeout (in seconds) to wait for incoming connections.</p>
<p>A value of -1 means infinite (default). This option implies the rtsp_flags set to ‘listen’.</p>
<p>reorder_queue_size
Set number of packets to buffer for handling of reordered packets.</p>
<p>stimeout
Set socket TCP I/O timeout in microseconds.</p>
<p>user-agent
Override User-Agent header. If not specified, it defaults to the libavformat identifier string.</p>
<p>When receiving data over UDP, the demuxer tries to reorder received packets (since they may arrive out of order, or packets may get lost totally). This can be disabled by setting the maximum demuxing delay to zero (via the max_delay field of AVFormatContext).</p>
<p>When watching multi-bitrate Real-RTSP streams with ffplay, the streams to display can be chosen with -vst n and -ast n for video and audio respectively, and can be switched on the fly by pressing v and a.</p>
<p>3.28.1 Examples
The following examples all make use of the ffplay and ffmpeg tools.</p>
<p>Watch a stream over UDP, with a max reordering delay of 0.5 seconds:
ffplay -max_delay 500000 -rtsp_transport udp <a class="reference external" href="rtsp://server/video.mp4">rtsp://server/video.mp4</a>
Watch a stream tunneled over HTTP:
ffplay -rtsp_transport http <a class="reference external" href="rtsp://server/video.mp4">rtsp://server/video.mp4</a>
Send a stream in realtime to a RTSP server, for others to watch:
ffmpeg -re -i input -f rtsp -muxdelay 0.1 <a class="reference external" href="rtsp://server/live.sdp">rtsp://server/live.sdp</a>
Receive a stream in realtime:
ffmpeg -rtsp_flags listen -i <a class="reference external" href="rtsp://ownaddress/live.sdp">rtsp://ownaddress/live.sdp</a> output
3.29 sap
Session Announcement Protocol (RFC 2974). This is not technically a protocol handler in libavformat, it is a muxer and demuxer. It is used for signalling of RTP streams, by announcing the SDP for the streams regularly on a separate port.</p>
<p>3.29.1 Muxer
The syntax for a SAP url given to the muxer is:</p>
<p>sap://destination[:port][?options]
The RTP packets are sent to destination on port port, or to port 5004 if no port is specified. options is a &amp;-separated list. The following options are supported:</p>
<p>announce_addr=address
Specify the destination IP address for sending the announcements to. If omitted, the announcements are sent to the commonly used SAP announcement multicast address 224.2.127.254 (sap.mcast.net), or ff0e::2:7ffe if destination is an IPv6 address.</p>
<p>announce_port=port
Specify the port to send the announcements on, defaults to 9875 if not specified.</p>
<p>ttl=ttl
Specify the time to live value for the announcements and RTP packets, defaults to 255.</p>
<p>same_port=0|1
If set to 1, send all RTP streams on the same port pair. If zero (the default), all streams are sent on unique ports, with each stream on a port 2 numbers higher than the previous. VLC/Live555 requires this to be set to 1, to be able to receive the stream. The RTP stack in libavformat for receiving requires all streams to be sent on unique ports.</p>
<p>Example command lines follow.</p>
<p>To broadcast a stream on the local subnet, for watching in VLC:</p>
<p>ffmpeg -re -i input -f sap sap://224.0.0.255?same_port=1
Similarly, for watching in ffplay:</p>
<p>ffmpeg -re -i input -f sap sap://224.0.0.255
And for watching in ffplay, over IPv6:</p>
<p>ffmpeg -re -i input -f sap sap://[ff0e::1:2:3:4]
3.29.2 Demuxer
The syntax for a SAP url given to the demuxer is:</p>
<p>sap://[address][:port]
address is the multicast address to listen for announcements on, if omitted, the default 224.2.127.254 (sap.mcast.net) is used. port is the port that is listened on, 9875 if omitted.</p>
<p>The demuxers listens for announcements on the given address and port. Once an announcement is received, it tries to receive that particular stream.</p>
<p>Example command lines follow.</p>
<p>To play back the first stream announced on the normal SAP multicast address:</p>
<p>ffplay sap://
To play back the first stream announced on one the default IPv6 SAP multicast address:</p>
<p>ffplay sap://[ff0e::2:7ffe]
3.30 sctp
Stream Control Transmission Protocol.</p>
<p>The accepted URL syntax is:</p>
<p>sctp://host:port[?options]
The protocol accepts the following options:</p>
<p>listen
If set to any value, listen for an incoming connection. Outgoing connection is done by default.</p>
<p>max_streams
Set the maximum number of streams. By default no limit is set.</p>
<p>3.31 srt
Haivision Secure Reliable Transport Protocol via libsrt.</p>
<p>The supported syntax for a SRT URL is:</p>
<p>srt://hostname:port[?options]
options contains a list of &amp;-separated options of the form key=val.</p>
<p>or</p>
<p>options srt://hostname:port
options contains a list of ’-key val’ options.</p>
<p>This protocol accepts the following options.</p>
<p>connect_timeout
Connection timeout; SRT cannot connect for RTT &gt; 1500 msec (2 handshake exchanges) with the default connect timeout of 3 seconds. This option applies to the caller and rendezvous connection modes. The connect timeout is 10 times the value set for the rendezvous mode (which can be used as a workaround for this connection problem with earlier versions).</p>
<p>ffs=bytes
Flight Flag Size (Window Size), in bytes. FFS is actually an internal parameter and you should set it to not less than recv_buffer_size and mss. The default value is relatively large, therefore unless you set a very large receiver buffer, you do not need to change this option. Default value is 25600.</p>
<p>inputbw=bytes/seconds
Sender nominal input rate, in bytes per seconds. Used along with oheadbw, when maxbw is set to relative (0), to calculate maximum sending rate when recovery packets are sent along with the main media stream: inputbw * (100 + oheadbw) / 100 if inputbw is not set while maxbw is set to relative (0), the actual input rate is evaluated inside the library. Default value is 0.</p>
<p>iptos=tos
IP Type of Service. Applies to sender only. Default value is 0xB8.</p>
<p>ipttl=ttl
IP Time To Live. Applies to sender only. Default value is 64.</p>
<p>latency
Timestamp-based Packet Delivery Delay. Used to absorb bursts of missed packet retransmissions. This flag sets both rcvlatency and peerlatency to the same value. Note that prior to version 1.3.0 this is the only flag to set the latency, however this is effectively equivalent to setting peerlatency, when side is sender and rcvlatency when side is receiver, and the bidirectional stream sending is not supported.</p>
<p>listen_timeout
Set socket listen timeout.</p>
<p>maxbw=bytes/seconds
Maximum sending bandwidth, in bytes per seconds. -1 infinite (CSRTCC limit is 30mbps) 0 relative to input rate (see inputbw) &gt;0 absolute limit value Default value is 0 (relative)</p>
<p>mode=caller|listener|rendezvous
Connection mode. caller opens client connection. listener starts server to listen for incoming connections. rendezvous use Rendez-Vous connection mode. Default value is caller.</p>
<p>mss=bytes
Maximum Segment Size, in bytes. Used for buffer allocation and rate calculation using a packet counter assuming fully filled packets. The smallest MSS between the peers is used. This is 1500 by default in the overall internet. This is the maximum size of the UDP packet and can be only decreased, unless you have some unusual dedicated network settings. Default value is 1500.</p>
<p>nakreport=1|0
If set to 1, Receiver will send ‘UMSG_LOSSREPORT‘ messages periodically until a lost packet is retransmitted or intentionally dropped. Default value is 1.</p>
<p>oheadbw=percents
Recovery bandwidth overhead above input rate, in percents. See inputbw. Default value is 25%.</p>
<p>passphrase=string
HaiCrypt Encryption/Decryption Passphrase string, length from 10 to 79 characters. The passphrase is the shared secret between the sender and the receiver. It is used to generate the Key Encrypting Key using PBKDF2 (Password-Based Key Derivation Function). It is used only if pbkeylen is non-zero. It is used on the receiver only if the received data is encrypted. The configured passphrase cannot be recovered (write-only).</p>
<p>payload_size=bytes
Sets the maximum declared size of a packet transferred during the single call to the sending function in Live mode. Use 0 if this value isn’t used (which is default in file mode). Default is -1 (automatic), which typically means MPEG-TS; if you are going to use SRT to send any different kind of payload, such as, for example, wrapping a live stream in very small frames, then you can use a bigger maximum frame size, though not greater than 1456 bytes.</p>
<p>pkt_size=bytes
Alias for ‘payload_size’.</p>
<p>peerlatency
The latency value (as described in rcvlatency) that is set by the sender side as a minimum value for the receiver.</p>
<p>pbkeylen=bytes
Sender encryption key length, in bytes. Only can be set to 0, 16, 24 and 32. Enable sender encryption if not 0. Not required on receiver (set to 0), key size obtained from sender in HaiCrypt handshake. Default value is 0.</p>
<p>rcvlatency
The time that should elapse since the moment when the packet was sent and the moment when it’s delivered to the receiver application in the receiving function. This time should be a buffer time large enough to cover the time spent for sending, unexpectedly extended RTT time, and the time needed to retransmit the lost UDP packet. The effective latency value will be the maximum of this options’ value and the value of peerlatency set by the peer side. Before version 1.3.0 this option is only available as latency.</p>
<p>recv_buffer_size=bytes
Set UDP receive buffer size, expressed in bytes.</p>
<p>send_buffer_size=bytes
Set UDP send buffer size, expressed in bytes.</p>
<p>rw_timeout
Set raise error timeout for read/write optations.</p>
<p>This option is only relevant in read mode: if no data arrived in more than this time interval, raise error.</p>
<p>tlpktdrop=1|0
Too-late Packet Drop. When enabled on receiver, it skips missing packets that have not been delivered in time and delivers the following packets to the application when their time-to-play has come. It also sends a fake ACK to the sender. When enabled on sender and enabled on the receiving peer, the sender drops the older packets that have no chance of being delivered in time. It was automatically enabled in the sender if the receiver supports it.</p>
<p>sndbuf=bytes
Set send buffer size, expressed in bytes.</p>
<p>rcvbuf=bytes
Set receive buffer size, expressed in bytes.</p>
<p>Receive buffer must not be greater than ffs.</p>
<p>lossmaxttl=packets
The value up to which the Reorder Tolerance may grow. When Reorder Tolerance is &gt; 0, then packet loss report is delayed until that number of packets come in. Reorder Tolerance increases every time a “belated” packet has come, but it wasn’t due to retransmission (that is, when UDP packets tend to come out of order), with the difference between the latest sequence and this packet’s sequence, and not more than the value of this option. By default it’s 0, which means that this mechanism is turned off, and the loss report is always sent immediately upon experiencing a “gap” in sequences.</p>
<p>minversion
The minimum SRT version that is required from the peer. A connection to a peer that does not satisfy the minimum version requirement will be rejected.</p>
<p>The version format in hex is 0xXXYYZZ for x.y.z in human readable form.</p>
<p>streamid=string
A string limited to 512 characters that can be set on the socket prior to connecting. This stream ID will be able to be retrieved by the listener side from the socket that is returned from srt_accept and was connected by a socket with that set stream ID. SRT does not enforce any special interpretation of the contents of this string. This option doesn’t make sense in Rendezvous connection; the result might be that simply one side will override the value from the other side and it’s the matter of luck which one would win</p>
<p>smoother=live|file
The type of Smoother used for the transmission for that socket, which is responsible for the transmission and congestion control. The Smoother type must be exactly the same on both connecting parties, otherwise the connection is rejected.</p>
<p>messageapi=1|0
When set, this socket uses the Message API, otherwise it uses Buffer API. Note that in live mode (see transtype) there’s only message API available. In File mode you can chose to use one of two modes:</p>
<p>Stream API (default, when this option is false). In this mode you may send as many data as you wish with one sending instruction, or even use dedicated functions that read directly from a file. The internal facility will take care of any speed and congestion control. When receiving, you can also receive as many data as desired, the data not extracted will be waiting for the next call. There is no boundary between data portions in the Stream mode.</p>
<p>Message API. In this mode your single sending instruction passes exactly one piece of data that has boundaries (a message). Contrary to Live mode, this message may span across multiple UDP packets and the only size limitation is that it shall fit as a whole in the sending buffer. The receiver shall use as large buffer as necessary to receive the message, otherwise the message will not be given up. When the message is not complete (not all packets received or there was a packet loss) it will not be given up.</p>
<p>transtype=live|file
Sets the transmission type for the socket, in particular, setting this option sets multiple other parameters to their default values as required for a particular transmission type.</p>
<p>live: Set options as for live transmission. In this mode, you should send by one sending instruction only so many data that fit in one UDP packet, and limited to the value defined first in payload_size (1316 is default in this mode). There is no speed control in this mode, only the bandwidth control, if configured, in order to not exceed the bandwidth with the overhead transmission (retransmitted and control packets).</p>
<p>file: Set options as for non-live transmission. See messageapi for further explanations</p>
<p>For more information see: <a class="reference external" href="https://github.com/Haivision/srt">https://github.com/Haivision/srt</a>.</p>
<p>3.32 srtp
Secure Real-time Transport Protocol.</p>
<p>The accepted options are:</p>
<p>srtp_in_suite
srtp_out_suite
Select input and output encoding suites.</p>
<p>Supported values:</p>
<p>‘AES_CM_128_HMAC_SHA1_80’
‘SRTP_AES128_CM_HMAC_SHA1_80’
‘AES_CM_128_HMAC_SHA1_32’
‘SRTP_AES128_CM_HMAC_SHA1_32’
srtp_in_params
srtp_out_params
Set input and output encoding parameters, which are expressed by a base64-encoded representation of a binary block. The first 16 bytes of this binary block are used as master key, the following 14 bytes are used as master salt.</p>
<p>3.33 subfile
Virtually extract a segment of a file or another stream. The underlying stream must be seekable.</p>
<p>Accepted options:</p>
<p>start
Start offset of the extracted segment, in bytes.</p>
<p>end
End offset of the extracted segment, in bytes. If set to 0, extract till end of file.</p>
<p>Examples:</p>
<p>Extract a chapter from a DVD VOB file (start and end sectors obtained externally and multiplied by 2048):</p>
<p>subfile,,start,153391104,end,268142592,,:/media/dvd/VIDEO_TS/VTS_08_1.VOB
Play an AVI file directly from a TAR archive:</p>
<p>subfile,,start,183241728,end,366490624,,:archive.tar
Play a MPEG-TS file from start offset till end:</p>
<p>subfile,,start,32815239,end,0,,:video.ts
3.34 tee
Writes the output to multiple protocols. The individual outputs are separated by |</p>
<p>tee:file://path/to/local/this.avi|file://path/to/local/that.avi
3.35 tcp
Transmission Control Protocol.</p>
<p>The required syntax for a TCP url is:</p>
<p><a class="reference external" href="tcp://hostname">tcp://hostname</a>:port[?options]
options contains a list of &amp;-separated options of the form key=val.</p>
<p>The list of supported options follows.</p>
<p>listen=1|0
Listen for an incoming connection. Default value is 0.</p>
<p>timeout=microseconds
Set raise error timeout, expressed in microseconds.</p>
<p>This option is only relevant in read mode: if no data arrived in more than this time interval, raise error.</p>
<p>listen_timeout=milliseconds
Set listen timeout, expressed in milliseconds.</p>
<p>recv_buffer_size=bytes
Set receive buffer size, expressed bytes.</p>
<p>send_buffer_size=bytes
Set send buffer size, expressed bytes.</p>
<p>tcp_nodelay=1|0
Set TCP_NODELAY to disable Nagle’s algorithm. Default value is 0.</p>
<p>tcp_mss=bytes
Set maximum segment size for outgoing TCP packets, expressed in bytes.</p>
<p>The following example shows how to setup a listening TCP connection with ffmpeg, which is then accessed with ffplay:</p>
<p>ffmpeg -i input -f format <a class="reference external" href="tcp://hostname:port?listen">tcp://hostname:port?listen</a>
ffplay <a class="reference external" href="tcp://hostname:port">tcp://hostname:port</a>
3.36 tls
Transport Layer Security (TLS) / Secure Sockets Layer (SSL)</p>
<p>The required syntax for a TLS/SSL url is:</p>
<p>tls://hostname:port[?options]
The following parameters can be set via command line options (or in code via AVOptions):</p>
<p>ca_file, cafile=filename
A file containing certificate authority (CA) root certificates to treat as trusted. If the linked TLS library contains a default this might not need to be specified for verification to work, but not all libraries and setups have defaults built in. The file must be in OpenSSL PEM format.</p>
<p>tls_verify=1|0
If enabled, try to verify the peer that we are communicating with. Note, if using OpenSSL, this currently only makes sure that the peer certificate is signed by one of the root certificates in the CA database, but it does not validate that the certificate actually matches the host name we are trying to connect to. (With other backends, the host name is validated as well.)</p>
<p>This is disabled by default since it requires a CA database to be provided by the caller in many cases.</p>
<p>cert_file, cert=filename
A file containing a certificate to use in the handshake with the peer. (When operating as server, in listen mode, this is more often required by the peer, while client certificates only are mandated in certain setups.)</p>
<p>key_file, key=filename
A file containing the private key for the certificate.</p>
<p>listen=1|0
If enabled, listen for connections on the provided port, and assume the server role in the handshake instead of the client role.</p>
<p>Example command lines:</p>
<p>To create a TLS/SSL server that serves an input stream.</p>
<p>ffmpeg -i input -f format tls://hostname:port?listen&amp;cert=server.crt&amp;key=server.key
To play back a stream from the TLS/SSL server using ffplay:</p>
<p>ffplay tls://hostname:port
3.37 udp
User Datagram Protocol.</p>
<p>The required syntax for an UDP URL is:</p>
<p>udp://hostname:port[?options]
options contains a list of &amp;-separated options of the form key=val.</p>
<p>In case threading is enabled on the system, a circular buffer is used to store the incoming data, which allows one to reduce loss of data due to UDP socket buffer overruns. The fifo_size and overrun_nonfatal options are related to this buffer.</p>
<p>The list of supported options follows.</p>
<p>buffer_size=size
Set the UDP maximum socket buffer size in bytes. This is used to set either the receive or send buffer size, depending on what the socket is used for. Default is 64KB. See also fifo_size.</p>
<p>bitrate=bitrate
If set to nonzero, the output will have the specified constant bitrate if the input has enough packets to sustain it.</p>
<p>burst_bits=bits
When using bitrate this specifies the maximum number of bits in packet bursts.</p>
<p>localport=port
Override the local UDP port to bind with.</p>
<p>localaddr=addr
Local IP address of a network interface used for sending packets or joining multicast groups.</p>
<p>pkt_size=size
Set the size in bytes of UDP packets.</p>
<p>reuse=1|0
Explicitly allow or disallow reusing UDP sockets.</p>
<p>ttl=ttl
Set the time to live value (for multicast only).</p>
<p>connect=1|0
Initialize the UDP socket with connect(). In this case, the destination address can’t be changed with ff_udp_set_remote_url later. If the destination address isn’t known at the start, this option can be specified in ff_udp_set_remote_url, too. This allows finding out the source address for the packets with getsockname, and makes writes return with AVERROR(ECONNREFUSED) if “destination unreachable” is received. For receiving, this gives the benefit of only receiving packets from the specified peer address/port.</p>
<p>sources=address[,address]
Only receive packets sent from the specified addresses. In case of multicast, also subscribe to multicast traffic coming from these addresses only.</p>
<p>block=address[,address]
Ignore packets sent from the specified addresses. In case of multicast, also exclude the source addresses in the multicast subscription.</p>
<p>fifo_size=units
Set the UDP receiving circular buffer size, expressed as a number of packets with size of 188 bytes. If not specified defaults to 7*4096.</p>
<p>overrun_nonfatal=1|0
Survive in case of UDP receiving circular buffer overrun. Default value is 0.</p>
<p>timeout=microseconds
Set raise error timeout, expressed in microseconds.</p>
<p>This option is only relevant in read mode: if no data arrived in more than this time interval, raise error.</p>
<p>broadcast=1|0
Explicitly allow or disallow UDP broadcasting.</p>
<p>Note that broadcasting may not work properly on networks having a broadcast storm protection.</p>
<p>3.37.1 Examples
Use ffmpeg to stream over UDP to a remote endpoint:
ffmpeg -i input -f format udp://hostname:port
Use ffmpeg to stream in mpegts format over UDP using 188 sized UDP packets, using a large input buffer:
ffmpeg -i input -f mpegts udp://hostname:port?pkt_size=188&amp;buffer_size=65535
Use ffmpeg to receive over UDP from a remote endpoint:
ffmpeg -i udp://[multicast-address]:port …
3.38 unix
Unix local socket</p>
<p>The required syntax for a Unix socket URL is:</p>
<p>unix://filepath
The following parameters can be set via command line options (or in code via AVOptions):</p>
<p>timeout
Timeout in ms.</p>
<p>listen
Create the Unix socket in listening mode.</p>
</div>
<div class="section" id="see-also">
<h2>4 See Also<a class="headerlink" href="#see-also" title="永久链接至标题">¶</a></h2>
<p>ffmpeg, ffplay, ffprobe, libavformat</p>
</div>
<div class="section" id="authors">
<h2>5 Authors<a class="headerlink" href="#authors" title="永久链接至标题">¶</a></h2>
<p>The FFmpeg developers.</p>
<p>For details about the authorship, see the Git history of the project (git://source.ffmpeg.org/ffmpeg), e.g. by typing the command git log in the FFmpeg source directory, or browsing the online repository at http://source.ffmpeg.org.</p>
<p>Maintainers for the specific components are listed in the file MAINTAINERS in the source code tree.</p>
<p>This document was generated on June 11, 2019 using makeinfo.</p>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="ffmpeg-devices.html" class="btn btn-neutral float-right" title="FFmpeg Devices Documentation" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="ffmpeg-formats.html" class="btn btn-neutral float-left" title="FFmpeg Formats Documentation" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2019, BandCap

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>